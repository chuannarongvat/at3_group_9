{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e69b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import datetime\n",
    "import sys\n",
    "import traceback\n",
    "pd.set_option('display.max_column', 100)\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for data cleaning\n",
    "\n",
    "def convert_to_epoch(df):\n",
    "    depart_time = []  # Initialize the list to store departure times\n",
    "    depttime=df['segmentsDepartureTimeRaw']\n",
    "    for depttime in depttime :\n",
    "        ts = pd.Timestamp(depttime)\n",
    "        Hour = int(ts.hour)\n",
    "        Minute = int(ts.minute)\n",
    "        depart_time.append(f\"{Hour:02d}:{Minute:02d}\")  # Format the time as HH:MM\n",
    "    df['depart_time'] = depart_time # Create a DataFrame from the list\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def convert_travel_time(df):\n",
    "    # Define the duration string\n",
    "    duration_str = df['travelDuration']\n",
    "    total_minutes=[]\n",
    "    for duration in duration_str:\n",
    "        # Use regular expressions to extract hours and minutes\n",
    "        hours_match = re.search(r'(\\d+)H', duration)\n",
    "        minutes_match = re.search(r'(\\d+)M', duration)\n",
    "        # Initialize variables for hours and minutes\n",
    "        hours = 0\n",
    "        minutes = 0\n",
    "        # If the matches are found, convert them to integers\n",
    "        if hours_match:\n",
    "            hours = int(hours_match.group(1))\n",
    "            if minutes_match:\n",
    "                minutes = int(minutes_match.group(1))\n",
    "        # Calculate the total duration in minutes\n",
    "        total_minutes.append(hours * 60 + minutes)\n",
    "    \n",
    "    df['travelDuration_minutes']=total_minutes\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_csv(input_csv, output_parquet):\n",
    "    output_path= \"../data/processed/\"\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "        \n",
    "    df_itenary_cp = df[['searchDate', 'flightDate', 'startingAirport',\n",
    "                     'destinationAirport', 'travelDuration', 'isBasicEconomy',\n",
    "                      'isRefundable', 'isNonStop', 'totalFare', 'totalTravelDistance',\n",
    "                      'segmentsDepartureTimeRaw', 'segmentsAirlineCode', 'segmentsCabinCode']].copy()\n",
    "\n",
    "    df_itenary_cp['totalTravelDistance'] = df_itenary_cp['totalTravelDistance'].fillna('PT0H0M')\n",
    "    df_itenary_cp['searchDate'] = pd.to_datetime(df_itenary_cp['searchDate'].str.replace('-', ''),\n",
    "                                                 format='%Y%m%d', errors='coerce')\n",
    "    df_itenary_cp['flightDate'] = pd.to_datetime(df_itenary_cp['flightDate'].str.replace('-', ''),\n",
    "                                                 format='%Y%m%d', errors='coerce')\n",
    "    df_itenary_cp['segmentsCabinCode'] = df_itenary_cp['segmentsCabinCode'].str.replace('|', ',').str.split(',').str[0]\n",
    "    df_itenary_cp['segmentsDepartureTimeRaw'] = pd.to_datetime(\n",
    "        df_itenary_cp['segmentsDepartureTimeRaw'].str.replace('|', ',').str.split(',').str[0],\n",
    "        format='%Y-%m-%dT%H:%M:%S.%f%z', errors='coerce')\n",
    "\n",
    "    df_itenary_cp['segmentsAirlineCode'] = df_itenary_cp['segmentsAirlineCode'].str.replace('|', ',').str.split(',').str[0]\n",
    "\n",
    "    df_itenary_cp = df_itenary_cp.dropna()\n",
    "    df_itenary_cp = convert_to_epoch(df_itenary_cp)\n",
    "    df_itenary_cp = convert_travel_time(df_itenary_cp)\n",
    "\n",
    "    df_itenary_cp = df_itenary_cp[['searchDate', 'flightDate', 'startingAirport', 'destinationAirport',\n",
    "                                   'travelDuration_minutes', 'isBasicEconomy', 'isRefundable', 'isNonStop',\n",
    "                                  'totalFare', 'totalTravelDistance', 'depart_time',\n",
    "                                   'segmentsAirlineCode', 'segmentsCabinCode']]\n",
    "    \n",
    "\n",
    "    df_itenary_cp.to_parquet(output_path+output_parquet, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting csv to parquet file\n",
    "process_and_save_csv('../data/raw/DEN_full.csv','DEN_full.parquet')\n",
    "process_and_save_csv('../data/raw/MIA_full.csv','MIA_full.parquet')\n",
    "process_and_save_csv('../data/raw/LAX_full.csv','LAX_full.parquet')\n",
    "process_and_save_csv('../data/raw/CLT_full.csv','CLT_full.parquet')\n",
    "process_and_save_csv('../data/raw/BOS_full.csv','BOS_full.parquet')\n",
    "process_and_save_csv('../data/raw/ATL_full.csv','ATL_full.parquet')\n",
    "process_and_save_csv('../data/raw/SFO_full.csv','SFO_full.parquet')\n",
    "process_and_save_csv('../data/raw/EWR_full.csv','EWR_full.parquet')\n",
    "process_and_save_csv('../data/raw/ORD_full.csv','ORD_full.parquet')\n",
    "process_and_save_csv('../data/raw/LGA_full.csv','LGA_full.parquet')\n",
    "process_and_save_csv('../data/raw/DFW_full.csv','DFW_full.parquet')\n",
    "process_and_save_csv('../data/raw/IAD_full.csv','IAD_full.parquet')\n",
    "process_and_save_csv('../data/raw/OAK_full.csv','OAK_full.parquet')\n",
    "process_and_save_csv('../data/raw/PHL_full.csv','PHL_full.parquet')\n",
    "process_and_save_csv('../data/raw/JFK_full.csv','JFK_full.parquet')\n",
    "process_and_save_csv('../data/raw/DTW_full.csv','DTW_full.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32492c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the files to create a single file\n",
    "input_folder = '../data/processed/' \n",
    "output_folder= \"../data/processed/\"\n",
    "\n",
    "# Specify the output file where you want to save the merged data\n",
    "output_file = os.path.join(output_folder, 'full_file.parquet')\n",
    "\n",
    "# Create an empty DataFrame to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the .parquet files in the input folder and merge them\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith('.parquet'):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        df = pd.read_parquet(file_path)\n",
    "        merged_df = pd.concat([merged_df, df])\n",
    "\n",
    "# Save the merged data to a new .parquet file\n",
    "merged_df.to_parquet(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4102ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datafile\n",
    "df=pd.read_parquet('../data/processed/full_file.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348bf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions and corresponding values using a dictionary\n",
    "conditions = {\n",
    "    \"business\": 1,\n",
    "    \"business||business\": 1,\n",
    "    \"coach\": 2,\n",
    "    \"coach||coach\": 2,\n",
    "    \"coach||coach||coach\": 2,\n",
    "    \"first\": 3,\n",
    "    \"first||first\": 3,\n",
    "    \"first||first||first\": 3,\n",
    "    \"business||business||coach\": 5,\n",
    "    \"business||coach\": 5,\n",
    "    \"business||coach||business\": 5,\n",
    "    \"business||coach||coach\": 5,\n",
    "    \"business||first\": 5,\n",
    "    \"business||first||first\": 5,\n",
    "    \"coach||business\": 5,\n",
    "    \"coach||business||business\": 5,\n",
    "    \"coach||business||coach\": 5,\n",
    "    \"coach||business||first\": 5,\n",
    "    \"coach||coach||business\": 5,\n",
    "    \"coach||coach||business||coach\": 5,\n",
    "    \"coach||coach||coach||coach\": 5,\n",
    "    \"coach||coach||coach||first\": 5,\n",
    "    \"coach||coach||coach||premium coach\": 5,\n",
    "    \"coach||coach||first\": 5,\n",
    "    \"coach||coach||first||coach\": 5,\n",
    "    \"coach||coach||first||first\": 5,\n",
    "    \"coach||coach||premium coach\": 5,\n",
    "    \"coach||coach||premium coach||coach\": 5,\n",
    "    \"coach||coach||premium coach||premium coach\": 5,\n",
    "    \"coach||first\": 5,\n",
    "    \"coach||first||coach\": 5,\n",
    "    \"coach||first||first\": 5,\n",
    "    \"coach||premium coach\": 5,\n",
    "    \"coach||premium coach||coach\": 5,\n",
    "    \"coach||premium coach||premium coach\": 5,\n",
    "    \"first||business\": 5,\n",
    "    \"first||coach\": 5,\n",
    "    \"first||coach||business\": 5,\n",
    "    \"first||coach||coach\": 5,\n",
    "    \"first||coach||coach||coach\": 5,\n",
    "    \"first||coach||first\": 5,\n",
    "    \"first||first||coach\": 5,\n",
    "    \"first||first||coach||coach\": 5,\n",
    "    \"premium coach||business||coach\": 5,\n",
    "    \"premium coach||coach\": 5,\n",
    "    \"premium coach||coach||coach\": 5,\n",
    "    \"premium coach||coach||coach||coach\": 5,\n",
    "    \"premium coach||first\": 5,\n",
    "    \"premium coach||premium coach||coach\": 5,\n",
    "    \"premium coach\": 4,\n",
    "    \"premium coach||premium coach\": 4,\n",
    "    \"premium coach||premium coach||premium coach\": 4\n",
    "}\n",
    "\n",
    "# Use numpy.select to set 'segmentsCabinCodeNum' based on conditions\n",
    "df['segmentsCabinCodeNum'] = np.select([df['segmentsCabinCode'] == cond for cond in conditions.keys()], list(conditions.values()), default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eecb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features for modeling\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "# Convert 'searchDate' to Unix timestamps\n",
    "df['searchDateNum'] = pd.to_datetime(df['searchDate']).astype(int) // 10**9\n",
    "df['flightDateNum'] = pd.to_datetime(df['flightDate']).astype(int) // 10**9\n",
    "if 'startingAirport' in df.columns: df['startingAirportNum'], _ = pd.factorize(df['startingAirport'])\n",
    "if 'destinationAirport' in df.columns: df['destinationAirportNum'], _ = pd.factorize(df['destinationAirport'])\n",
    "if 'segmentsArrivalAirportCode' in df.columns: \n",
    "    df['segmentsArrivalAirportCodeNum'], _ = pd.factorize(df['segmentsArrivalAirportCode'])\n",
    "if 'segmentsDepartureAirportCode' in df.columns: \n",
    "    df['segmentsDepartureAirportCodeNum'], _ = pd.factorize(df['segmentsDepartureAirportCode'])        \n",
    "    \n",
    "# Define a function to convert duration strings to 'x.xx' format\n",
    "def convert_duration(duration_str):\n",
    "    match = re.search(r'(\\d+)H(\\d+)M', duration_str)\n",
    "    if match:\n",
    "        hours, minutes = map(int, match.groups())\n",
    "        total_hours = hours + minutes / 60.0\n",
    "        return '{:.2f}'.format(total_hours)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the conversion function to the 'travelDuration' column\n",
    "df['travelDuration_minutes']=df['travelDuration_minutes'].astype(str)\n",
    "if 'travelDuration_minutes' in df.columns: df['travelDurationNum'] = df['travelDuration_minutes'].apply(convert_duration)\n",
    "    \n",
    "    \n",
    "##########################################################################################\n",
    "\n",
    "df['segmentsDepartureTimeRawStr'] = df['segmentsDepartureTimeRaw'].astype(str)\n",
    "df['segmentsDepartureTimeRawStr'] = df['segmentsDepartureTimeRawStr'].str.split(r'\\|\\|').str[0]\n",
    "\n",
    "df['segmentsDepartureTimeRawStr'] = df['segmentsDepartureTimeRawStr'].apply(lambda x: parser.parse(x) if pd.notna(x) else None)\n",
    "df['day_of_week'] = df['segmentsDepartureTimeRawStr'].apply(lambda x: x.strftime('%A') if x else None)\n",
    "\n",
    "df['departure_month'] = df['segmentsDepartureTimeRawStr'].apply(lambda x: pd.to_datetime(x).month if pd.notna(x) else None)\n",
    "df['departure_time_bin'] = df['segmentsDepartureTimeRawStr'].apply(lambda x: (x.hour * 60 + x.minute) // 120)\n",
    "df['departure_month'] = df['segmentsDepartureTimeRawStr'].apply(lambda x: pd.to_datetime(x).month if pd.notna(x) else None)\n",
    "    \n",
    "##########################################################################################\n",
    "\n",
    "# Define a mapping from day names to numbers\n",
    "day_to_number = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "# Convert day of the week to a number\n",
    "df['departure_day_of_week'] = df['day_of_week'].map(day_to_number)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6717f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df.loc[df['totalTravelDistance'] == \"PT0H0M\", 'totalTravelDistance'] = \"0\"\n",
    "df['totalTravelDistance']=df['totalTravelDistance'].astype('float')\n",
    "df['totalFare']=df['totalFare'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea293328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 19217.47\n",
      "R-squared (R2): 0.55\n"
     ]
    }
   ],
   "source": [
    "# Model for gradient boost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define all features and target variable\n",
    "features = [\n",
    "    'startingAirportNum',\n",
    "    'destinationAirportNum',\n",
    "    'flightDateNum',  \n",
    "    'departure_time_bin',\n",
    "    'departure_day_of_week',\n",
    "    'departure_month',\n",
    "    'segmentsCabinCodeNum'   \n",
    "]\n",
    "\n",
    "target = 'totalFare'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gradient Boosting regression model\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the model's performance metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197eb7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_gb_boost.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model file\n",
    "from joblib import dump\n",
    "#dump(model,'../models/model_gb_boost_srusti.joblib')\n",
    "# Dump model file after compressing. The raw file was of size 153 MB due to which the heroku app was failing.\n",
    "dump(model,'../models/model_gb_boost.joblib', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d15dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9fede41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40883bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e09c8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa646b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
